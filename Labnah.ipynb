{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n"
      ],
      "metadata": {
        "id": "128P02Z80D7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dateparser\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "0_tGfBimV7pU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7b8085-6358-4d38-ede0-308564b2c69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (5.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser) (1.17.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import csv\n",
        "import ast\n",
        "import joblib\n",
        "import cloudpickle\n",
        "import requests\n",
        "import dateparser\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from scipy.stats import kendalltau\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import (\n",
        "    FunctionTransformer,\n",
        "    MultiLabelBinarizer,\n",
        "    OneHotEncoder,\n",
        "    StandardScaler\n",
        ")\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.offline import plot, iplot, init_notebook_mode"
      ],
      "metadata": {
        "id": "Gx7ipLOH0LaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading CSVs & Merging"
      ],
      "metadata": {
        "id": "uyZPOJ_duq-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGIPEoxaNL3C",
        "outputId": "71c184f2-ab21-4b4e-a726-295973b9418e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLmaQLwVB0Q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b09b5d-d9aa-4f13-bca8-8a87b60937b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4919daebc621>:4: DtypeWarning:\n",
            "\n",
            "Columns (0,2,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_demo = pd.read_csv('/content/drive/MyDrive/ML DataSet/demos.csv')\n",
        "df_dlc = pd.read_csv('/content/drive/MyDrive/ML DataSet/dlcs.csv')\n",
        "df_steam = pd.read_csv('/content/drive/MyDrive/ML DataSet/gamalytic_steam_games.csv')\n",
        "df_info = pd.read_csv('/content/drive/MyDrive/ML DataSet/info_base_games.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_game_dataframes(df_info, df_steam, df_dlc, df_demo):\n",
        "\n",
        "    df_demo.rename(columns={'full_game_appid': 'steam_id'}, inplace=True)\n",
        "    df_dlc.rename(columns={'base_appid': 'steam_id'}, inplace=True)\n",
        "    df_steam.rename(columns={'steamId': 'steam_id'}, inplace=True)\n",
        "    df_info.rename(columns={'appid': 'steam_id'}, inplace=True)\n",
        "\n",
        "    df_info.rename(columns={'name': 'name_info'}, inplace=True)\n",
        "    df_dlc.rename(columns={'name': 'name_dlc'}, inplace=True)\n",
        "    df_demo.rename(columns={'name': 'name_demo'}, inplace=True)\n",
        "\n",
        "    df_info['steam_id'] = df_info['steam_id'].astype(str)\n",
        "    df_steam['steam_id'] = df_steam['steam_id'].astype(str)\n",
        "    df_dlc['steam_id'] = df_dlc['steam_id'].astype(str)\n",
        "    df_demo['steam_id'] = df_demo['steam_id'].astype(str)\n",
        "\n",
        "    final_df = pd.merge(df_info, df_steam, on='steam_id', how='outer')\n",
        "    final_df = pd.merge(final_df, df_dlc[['steam_id', 'dlc_appid', 'name_dlc']], on='steam_id', how='left')\n",
        "    final_df = pd.merge(final_df, df_demo[['steam_id', 'demo_appid', 'name_demo']], on='steam_id', how='left')\n",
        "\n",
        "    return final_df\n",
        "\n",
        "intial_df = merge_game_dataframes(df_info, df_steam, df_dlc, df_demo)\n",
        "\n",
        "# Dropping Unnecessary columns\n",
        "intial_df = intial_df.drop('aiContent', axis=1)\n",
        "#intial_df = intial_df.drop('Unnamed: 0', axis=1)\n",
        "intial_df = intial_df.drop('name_demo', axis=1)\n",
        "intial_df = intial_df.drop('name_dlc', axis=1)"
      ],
      "metadata": {
        "id": "a4nH5INIv20d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fetching Data**"
      ],
      "metadata": {
        "id": "SZ1TOqsE0Xm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch_pipeline = joblib.load('fetch_pipeline.joblib')\n",
        "# fetch_df = fetch_pipeline.fit_transform(intial_df)\n",
        "fetch_df = pd.read_csv('/content/drive/MyDrive/ML DataSet/last.csv')\n",
        "initial_selected = intial_df[['steam_id', 'copiesSold', 'reviewScore', 'publisherClass']]\n",
        "fetch_df['steam_id'] = fetch_df['steam_id'].astype(str)\n",
        "fetch_df = fetch_df.merge(initial_selected, on='steam_id', how='left')"
      ],
      "metadata": {
        "id": "j5t4OFON0XBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_df = fetch_df.drop('demo_appid', axis=1)\n",
        "fetch_df = fetch_df.drop('dlc_appid', axis=1)"
      ],
      "metadata": {
        "id": "eZf2b_4-w5Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping duplicates due to fetching and null copies sold\n",
        "print(fetch_df.duplicated().sum())\n",
        "fetch_df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "LKlKq3fv9FBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb637c93-8aa0-4871-923e-49abe52402e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BmhJEJvpWCo",
        "outputId": "3a9807bc-af0d-411c-d6a4-94c210277000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118227, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4CNjmSgqVKQ",
        "outputId": "818a682e-4f1f-445f-c4b0-05a25a8c2a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['steam_id', 'name_info', 'metacritic', 'steam_achievements',\n",
              "       'steam_trading_cards', 'workshop_support', 'genres',\n",
              "       'achievements_total', 'release_date', 'coming_soon', 'support_windows',\n",
              "       'support_mac', 'support_linux', 'has_dlc', 'has_demo', 'name_dlc',\n",
              "       'name_demo', 'publisher', 'developer', 'is_free', 'controller_support',\n",
              "       'recommendations', 'age_rating', 'languages_clean_str', 'price',\n",
              "       'copiesSold', 'reviewScore', 'publisherClass'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the data"
      ],
      "metadata": {
        "id": "kOuye8k4GqRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train(df): 70%, validation(val_df): 15%, test(test_df): 15%\n",
        "df, temp_df = train_test_split(fetch_df, test_size=0.30, random_state=42)\n",
        "# Step 2: Split temp into validation and test\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=42)"
      ],
      "metadata": {
        "id": "R0SJsrLtHXd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying the preprocessing pipeline"
      ],
      "metadata": {
        "id": "zw9nEn2zyga8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Should be called if Regression only (first function)\n",
        "def update_coming_soon_inplace(df):\n",
        "    condition_coming_soon = (df['coming_soon'] == 1) & (df['copiesSold'].isna())\n",
        "    df.loc[condition_coming_soon & (df['is_free'] == 1), ['price', 'reviewScore', 'recommendations', 'copiesSold']] = 0\n",
        "    df.loc[condition_coming_soon, ['reviewScore', 'recommendations', 'copiesSold']] = 0\n",
        "    return df\n",
        "def drop_copies_sold_na(df):\n",
        "    df.dropna(subset=['copiesSold'], inplace=True)\n",
        "    return df\n",
        "def preprocess_publisher_data(df):\n",
        "    publisher_class_mapping = {\n",
        "        0: 'AAA',\n",
        "        1: 'Indie',\n",
        "        2: 'AA',\n",
        "        3: 'Hobbyist',\n",
        "        4: 'Other'\n",
        "    }\n",
        "\n",
        "    valid_class_names = {\n",
        "        'AAA': 0,\n",
        "        'Indie': 1,\n",
        "        'AA': 2,\n",
        "        'Hobbyist': 3,\n",
        "        'Other': 4\n",
        "    }\n",
        "\n",
        "    if 'publisher' in df.columns and 'publisherClass' in df.columns:\n",
        "        df['publisherClass'] = df['publisherClass'].fillna(-1)\n",
        "        if not df.empty:\n",
        "            df['publisherClass'] = df['publisherClass'].replace(valid_class_names)\n",
        "            df['publisherClass'] = df['publisherClass'].apply(lambda x: 4 if isinstance(x, str) else x)\n",
        "\n",
        "    return df\n",
        "def fill_publisher_class(df):\n",
        "    if 'publisher' in df.columns and 'publisherClass' in df.columns:\n",
        "        values_to_fill_mask = (df['publisherClass'] == -1) | (df['publisherClass'].isna())\n",
        "        publisher_mode_mapping = df[~values_to_fill_mask].groupby('publisher')['publisherClass'].agg(\n",
        "            lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
        "        ).to_dict()\n",
        "        mode_for_each_row = df['publisher'].map(publisher_mode_mapping)\n",
        "        fill_locations = values_to_fill_mask & mode_for_each_row.notna()\n",
        "        df.loc[fill_locations, 'publisherClass'] = mode_for_each_row[fill_locations]\n",
        "    elif 'developer' in df.columns and 'publisherClass' in df.columns:\n",
        "        values_to_fill_mask = (df['publisherClass'] == -1) | (df['publisherClass'].isna())\n",
        "        valid_df = df[~values_to_fill_mask]\n",
        "        if not valid_df.empty:\n",
        "            developer_mode_mapping = valid_df.groupby('developer')['publisherClass'].agg(\n",
        "                lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
        "            ).to_dict()\n",
        "            mode_for_each_row = df['developer'].map(developer_mode_mapping)\n",
        "            fill_locations = values_to_fill_mask & mode_for_each_row.notna()\n",
        "            df.loc[fill_locations, 'publisherClass'] = mode_for_each_row[fill_locations]\n",
        "    else:\n",
        "        if 'publisherClass' in df.columns:\n",
        "            mode_val = df['publisherClass'].mode()\n",
        "            if not mode_val.empty:\n",
        "                df['publisherClass'].fillna(mode_val[0], inplace=True)\n",
        "                df.loc[df['publisherClass'] == -1, 'publisherClass'] = mode_val[0]\n",
        "    return df\n",
        "def is_missing_price(series):\n",
        "    mask = series.isna()\n",
        "    if pd.api.types.is_string_dtype(series):\n",
        "        mask = mask | (series == '') | (series.str.strip() == '')\n",
        "    return mask\n",
        "\n",
        "def fill_price_hierarchically_inplace(df):\n",
        "    if 'price' in df.columns:\n",
        "        df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
        "\n",
        "    if {'price', 'publisher'}.issubset(df.columns):\n",
        "        initial_mask = is_missing_price(df['price'])\n",
        "        valid_df = df[~is_missing_price(df['price']) & ~is_missing_price(df['publisher'])]\n",
        "        publisher_means = valid_df.groupby('publisher')['price'].mean().to_dict()\n",
        "        mapped_publisher_mean = df['publisher'].map(publisher_means)\n",
        "        fill_mask = initial_mask & df['publisher'].notna() & mapped_publisher_mean.notna()\n",
        "        df.loc[fill_mask, 'price'] = mapped_publisher_mean[fill_mask]\n",
        "\n",
        "    elif {'price', 'developer'}.issubset(df.columns):\n",
        "        remaining_mask = is_missing_price(df['price'])\n",
        "        valid_df = df[~is_missing_price(df['price']) & ~is_missing_price(df['developer'])]\n",
        "        developer_means = valid_df.groupby('developer')['price'].mean().to_dict()\n",
        "        mapped_dev_mean = df['developer'].map(developer_means)\n",
        "        fill_mask = remaining_mask & df['developer'].notna() & mapped_dev_mean.notna()\n",
        "        df.loc[fill_mask, 'price'] = mapped_dev_mean[fill_mask]\n",
        "\n",
        "    else:\n",
        "        df['price'].fillna(df['price'].mean(), inplace=True)\n",
        "    return df\n",
        "def translate_genres(df):\n",
        "    genre_translation = {\n",
        "        'Acción': 'Action', 'Ação': 'Action', 'アクション': 'Action', 'Экшены': 'Action',\n",
        "        'Aventura': 'Adventure', 'Приключенческие игры': 'Adventure', 'アドベンチャー': 'Adventure',\n",
        "        'Casual': 'Casual', 'Казуальные игры': 'Casual', 'カジュアル': 'Casual', 'Indépendant': 'Indie',\n",
        "        'Инди': 'Indie', 'インディー': 'Indie', 'Simuladores': 'Simulation', 'シミュレーション': 'Simulation',\n",
        "        'Stratégie': 'Strategy', 'Estrategia': 'Strategy', 'Strategie': 'Strategy', 'Sport': 'Sports',\n",
        "        'Course automobile': 'Racing', 'Бесплатные': 'Free To Play', 'Grátis para Jogar': 'Free To Play',\n",
        "        '無料プレイ': 'Free To Play', 'Accès anticipé': 'Early Access', 'Ранний доступ': 'Early Access',\n",
        "        '早期アクセス': 'Early Access', 'Ролевые игры': 'RPG', 'Violent': 'Violent', 'Gore': 'Gore',\n",
        "        'Nudity': 'Nudity', 'Sexual Content': 'Sexual Content', 'MM（Massively Multiplayer）': 'Massively Multiplayer',\n",
        "        '액션': 'Action', 'Бесплатные': 'Free To Play', 'Ролевые игры': 'RPG', 'Экшены': 'Action', 'Tutorial': 'Software Training',\n",
        "        'Documentary': 'Education', 'Short': 'Creative Tools', 'Movie': 'Creative Tools'\n",
        "    }\n",
        "\n",
        "    if 'genres' in df.columns:\n",
        "        def safe_translate(genre):\n",
        "            if pd.isna(genre) or not isinstance(genre, str):\n",
        "                return 'Unknown'\n",
        "\n",
        "            try:\n",
        "                base_genre = genre.split('（')[0].strip().replace('）', '')\n",
        "                return genre_translation.get(base_genre, genre)\n",
        "            except (AttributeError, TypeError):\n",
        "                return genre\n",
        "\n",
        "        df['genres'] = df['genres'].apply(safe_translate)\n",
        "    else:\n",
        "        df['genres'] = 'Unknown'\n",
        "\n",
        "    return df\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def is_missing_or_unknown_genre(series):\n",
        "    # Start with basic missing value check\n",
        "    mask = series.isna()\n",
        "\n",
        "    # Check for empty strings if string type\n",
        "    if pd.api.types.is_string_dtype(series):\n",
        "        mask = mask | (series == '') | (series.str.strip() == '')\n",
        "        # Also check for \"Unknown\" values\n",
        "        mask = mask | (series.str.lower() == 'unknown')\n",
        "\n",
        "    # Check for empty lists if any list values\n",
        "    if series.apply(lambda x: isinstance(x, list)).any():\n",
        "        mask = mask | series.apply(lambda x: isinstance(x, list) and len(x) == 0)\n",
        "\n",
        "    return mask\n",
        "\n",
        "def fill_missing_genres(df):\n",
        "    # Make a copy to avoid modifying the original\n",
        "    df = df.copy()\n",
        "\n",
        "    required_cols = ['genres', 'publisher']\n",
        "    if all(col in df.columns for col in required_cols):\n",
        "        # Identify rows with missing or \"Unknown\" genres\n",
        "        initial_genres_to_fill_mask = is_missing_or_unknown_genre(df['genres'])\n",
        "        valid_genres_for_publisher_mode = df[~is_missing_or_unknown_genre(df['genres'])]\n",
        "\n",
        "        publisher_mode_mapping = {}\n",
        "        if not valid_genres_for_publisher_mode.empty:\n",
        "            valid_publishers_df = valid_genres_for_publisher_mode[~is_missing_or_unknown_genre(valid_genres_for_publisher_mode['publisher'])]\n",
        "            if not valid_publishers_df.empty:\n",
        "                publisher_mode_mapping = valid_publishers_df.groupby('publisher')['genres'].agg(\n",
        "                    lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
        "                ).to_dict()\n",
        "\n",
        "        publisher_mode_for_each_row = df['publisher'].map(publisher_mode_mapping)\n",
        "        fill_with_publisher_mask = initial_genres_to_fill_mask & ~is_missing_or_unknown_genre(df['publisher']) & publisher_mode_for_each_row.notna()\n",
        "        df.loc[fill_with_publisher_mask, 'genres'] = publisher_mode_for_each_row[fill_with_publisher_mask]\n",
        "\n",
        "    required_cols = ['genres', 'developer']\n",
        "    if all(col in df.columns for col in required_cols):\n",
        "        # Now work with remaining missing or \"Unknown\" genres\n",
        "        remaining_genres_to_fill_mask = is_missing_or_unknown_genre(df['genres'])\n",
        "        valid_genres_for_developer_mode = df[~is_missing_or_unknown_genre(df['genres'])]\n",
        "\n",
        "        developer_mode_mapping = {}\n",
        "        if not valid_genres_for_developer_mode.empty:\n",
        "            valid_developers_df = valid_genres_for_developer_mode[~is_missing_or_unknown_genre(valid_genres_for_developer_mode['developer'])]\n",
        "            if not valid_developers_df.empty:\n",
        "                developer_mode_mapping = valid_developers_df.groupby('developer')['genres'].agg(\n",
        "                    lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
        "                ).to_dict()\n",
        "\n",
        "        developer_mode_for_each_row = df['developer'].map(developer_mode_mapping)\n",
        "        fill_with_developer_mask = remaining_genres_to_fill_mask & ~is_missing_or_unknown_genre(df['developer']) & developer_mode_for_each_row.notna()\n",
        "        df.loc[fill_with_developer_mask, 'genres'] = developer_mode_for_each_row[fill_with_developer_mask]\n",
        "\n",
        "    # Finally fill any remaining missing or \"Unknown\" genres with global mode\n",
        "    if 'genres' in df.columns:\n",
        "        final_remaining_genres_to_fill_mask = is_missing_or_unknown_genre(df['genres'])\n",
        "        all_valid_genres = df[~is_missing_or_unknown_genre(df['genres'])]\n",
        "        global_mode_genre = np.nan\n",
        "\n",
        "        if not all_valid_genres.empty:\n",
        "            global_mode_genre = all_valid_genres['genres'].mode().iloc[0]\n",
        "\n",
        "        if pd.notna(global_mode_genre):\n",
        "            df.loc[final_remaining_genres_to_fill_mask, 'genres'] = global_mode_genre\n",
        "\n",
        "    return df\n",
        "def standardize_date(date_str):\n",
        "    coming_soon_phrases = ['to be announced', 'coming soon', 'maybe', 'em breve', 'binnenkort verwacht']\n",
        "    if any(phrase in str(date_str).lower() for phrase in coming_soon_phrases):\n",
        "        return (None, 1)\n",
        "\n",
        "    quarter_match = re.match(r'Q([1-4])\\s*(\\d{4})', str(date_str), re.IGNORECASE)\n",
        "    if quarter_match:\n",
        "        quarter = int(quarter_match.group(1))\n",
        "        year = int(quarter_match.group(2))\n",
        "        month = (quarter - 1) * 3 + 1\n",
        "        return (f\"{year}-{month:02d}-01\", 0)\n",
        "\n",
        "    if re.fullmatch(r'\\d{4}', str(date_str)):\n",
        "        return (f\"{date_str}-01-01\", 0)\n",
        "\n",
        "    parsed_date = dateparser.parse(\n",
        "        str(date_str),\n",
        "        languages=['en', 'ru', 'fr', 'es', 'zh', 'ko', 'de', 'nl', 'pt'],\n",
        "        settings={'PREFER_DAY_OF_MONTH': 'first'}\n",
        "    )\n",
        "\n",
        "    if parsed_date:\n",
        "        return (parsed_date.strftime(\"%Y-%m-%d\"), 0)\n",
        "    else:\n",
        "        return (None, 1)\n",
        "\n",
        "def apply_standardize_dates(df):\n",
        "    df[['standardized_date', 'coming_soon']] = df['release_date'].apply(\n",
        "        lambda x: pd.Series(standardize_date(x))\n",
        "    )\n",
        "    return df\n",
        "def categorize_genre(genre, category_map, default='Uncategorized'):\n",
        "\n",
        "    for category, subcategories in category_map.items():\n",
        "        if genre in subcategories:\n",
        "            return category\n",
        "    return default\n",
        "\n",
        "def update_genres_with_categories(df):\n",
        "\n",
        "    category_map = {\n",
        "        'Core Games': ['Action', 'Adventure', 'RPG', 'Strategy', 'Simulation', 'Episodic'],\n",
        "        'Casual & Social Games': [\n",
        "            'Casual', 'Free To Play', 'Massively Multiplayer', 'Early Access', 'MM（Massively Multiplayer）'\n",
        "        ],\n",
        "        'Sports & Racing': ['Sports', 'Racing'],\n",
        "        'Indie': ['Indie'],\n",
        "        'Education & Training': ['Education', 'Software Training', 'Documentary', 'Tutorial'],\n",
        "        'Creative Tools': [\n",
        "            'Animation & Modeling', 'Design & Illustration', 'Photo Editing',\n",
        "            'Video Production', 'Audio Production', 'Web Publishing',\n",
        "            'Game Development', 'Short', 'Movie'\n",
        "        ],\n",
        "        'Productivity Tools': ['Utilities', 'Accounting'],\n",
        "        'Mature Content': ['Violent', 'Gore', 'Nudity', 'Sexual Content']\n",
        "    }\n",
        "\n",
        "    exploded_genres = (\n",
        "        df['genres']\n",
        "        .str.split(r',\\s*')\n",
        "        .explode()\n",
        "        .str.strip()\n",
        "        .str.replace(r'[（）]', '', regex=True)\n",
        "        .to_frame()\n",
        "        .reset_index()\n",
        "    )\n",
        "    exploded_genres['category'] = exploded_genres['genres'].apply(\n",
        "        lambda g: categorize_genre(g, category_map=category_map)\n",
        "    )\n",
        "    df = df.join(\n",
        "        exploded_genres.groupby('index')['category']\n",
        "        .agg(lambda x: list(set(x)))\n",
        "        .rename('categories')\n",
        "    )\n",
        "\n",
        "    return df\n",
        "def count_total_languages(language_str):\n",
        "    if pd.isna(language_str) or language_str == \"No info\":\n",
        "        return 1\n",
        "    languages = [lang.strip() for lang in language_str.split(',') if lang.strip()]\n",
        "    return len(languages) if languages else 1\n",
        "\n",
        "def add_total_languages_column(df):\n",
        "    df['total_languages'] = df['languages_clean_str'].apply(count_total_languages)\n",
        "    return df\n",
        "def force_list(x):\n",
        "    if isinstance(x, (list, tuple, set)):\n",
        "        return list(x)\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "def MultiLabelBinarizer_encode_categories(df):\n",
        "    df['categories'] = df['categories'].apply(force_list)\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    onehot = mlb.fit_transform(df['categories'])\n",
        "    onehot_df = pd.DataFrame(onehot, columns=mlb.classes_, index=df.index)\n",
        "    df = pd.concat([df, onehot_df], axis=1)\n",
        "    return df\n",
        "def replace_age_rating(df):\n",
        "    df['age_rating'].replace('m', 17, inplace=True)\n",
        "    df['age_rating'].replace('z', 18, inplace=True)\n",
        "    df['age_rating'].replace('stats', 1, inplace=True)\n",
        "    df['age_rating'].replace('ec',3, inplace=True)\n",
        "    df['age_rating'].replace('b', 12, inplace=True)\n",
        "    df['age_rating'].replace('ao', 18, inplace=True)\n",
        "    df['age_rating'].replace('c', 15, inplace=True)\n",
        "    df['age_rating'].replace('rpm', 14, inplace=True)\n",
        "    df['age_rating'].replace('rp', 17, inplace=True)\n",
        "    df['age_rating'].replace('d', 17, inplace=True)\n",
        "    df['age_rating'].replace('e', 6, inplace=True)\n",
        "    df['age_rating'].replace('a', 1, inplace=True)\n",
        "    df['age_rating'].replace('e10', 10, inplace=True)\n",
        "    df['age_rating'].replace('t', 13, inplace=True)\n",
        "    df['age_rating'] = pd.to_numeric(df['age_rating'], errors='coerce')\n",
        "    return df\n",
        "def encode_supported_platforms(df):\n",
        "\n",
        "    df['supported_platforms'] = df['supported_platforms'].apply(\n",
        "        lambda x: ast.literal_eval(x) if pd.notna(x) and isinstance(x, str) else\n",
        "                 (x if isinstance(x, list) else [])\n",
        "    )\n",
        "\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    encoded = mlb.fit_transform(df['supported_platforms'])\n",
        "\n",
        "    encoded_df = pd.DataFrame(encoded, columns=mlb.classes_, index=df.index)\n",
        "    encoded_df.columns = ['support_' + col.lower() for col in encoded_df.columns]\n",
        "    result_df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "    return result_df\n",
        "def booleans_encoding(df):\n",
        "\n",
        "    boolean_features = [\n",
        "        'steam_achievements',\n",
        "        'steam_trading_cards',\n",
        "        'workshop_support'\n",
        "    ]\n",
        "    for feature in boolean_features:\n",
        "        if feature in df.columns:\n",
        "            df[feature] = df[feature].map({True: 1, False: 0}).fillna(-1)\n",
        "    df['has_demo'] = df[['demo_appid', 'name_demo']].notna().any(axis=1).astype(int)\n",
        "    df['has_dlc'] = df[['dlc_appid', 'name_dlc']].notna().any(axis=1).astype(int)\n",
        "    df['has_demo'] = df['has_demo'].fillna(0).astype(int)\n",
        "    df['has_dlc'] = df['has_dlc'].fillna(0).astype(int)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "nKKEfLFbtiOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "        ('update_coming_soon_inplace', FunctionTransformer(update_coming_soon_inplace, validate=False)),\n",
        "        ('preprocess_publisher_data', FunctionTransformer(preprocess_publisher_data, validate=False)),\n",
        "        ('fill_publisher_class', FunctionTransformer(fill_publisher_class, validate=False)),\n",
        "        ('fill_price_hierarchically_inplace', FunctionTransformer(fill_price_hierarchically_inplace, validate=False)),\n",
        "        ('translate_genres', FunctionTransformer(translate_genres, validate=False)),\n",
        "        ('fill_missing_genres', FunctionTransformer(fill_missing_genres, validate=False)),\n",
        "        ('apply_standardize_dates', FunctionTransformer(apply_standardize_dates, validate=False)),\n",
        "        ('update_genres_with_categories', FunctionTransformer(update_genres_with_categories, validate=False)),\n",
        "        ('add_total_languages_column', FunctionTransformer(add_total_languages_column, validate=False)),\n",
        "        ('MultiLabelBinarizer_encode_categories', FunctionTransformer(MultiLabelBinarizer_encode_categories, validate=False)),\n",
        "        ('replace_age_rating', FunctionTransformer(replace_age_rating, validate=False)),\n",
        "        #('encode_platforms', FunctionTransformer(encode_supported_platforms, validate=False)),\n",
        "        #('booleans_encoding', FunctionTransformer(booleans_encoding, validate=False))\n",
        "])\n",
        "joblib.dump(pipeline, 'pipeline.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W71zlBuSu6-O",
        "outputId": "0c4a8af2-ce5d-4e3c-9812-d47778049d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pipeline.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = joblib.load('pipeline.joblib')\n",
        "df = pipeline.fit_transform(df)"
      ],
      "metadata": {
        "id": "xm49m_WCy9Ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2573284f-43ca-419e-dafe-b8ad52083319"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-b34850d77b0a>:30: FutureWarning:\n",
            "\n",
            "Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:291: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:292: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:293: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:294: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:295: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:296: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:297: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:298: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:299: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:300: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:301: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:302: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:303: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n",
            "<ipython-input-12-b34850d77b0a>:304: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "id": "4o5LR0FOyA04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f4f901-1afc-4a11-afa1-c02c37e00db3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['steam_id', 'name_info', 'metacritic', 'steam_achievements',\n",
              "       'steam_trading_cards', 'workshop_support', 'genres',\n",
              "       'achievements_total', 'release_date', 'coming_soon', 'support_windows',\n",
              "       'support_mac', 'support_linux', 'has_dlc', 'has_demo', 'name_dlc',\n",
              "       'name_demo', 'publisher', 'developer', 'is_free', 'controller_support',\n",
              "       'recommendations', 'age_rating', 'languages_clean_str', 'price',\n",
              "       'copiesSold', 'reviewScore', 'publisherClass', 'standardized_date',\n",
              "       'categories', 'total_languages', 'Casual & Social Games', 'Core Games',\n",
              "       'Creative Tools', 'Education & Training', 'Indie', 'Mature Content',\n",
              "       'Productivity Tools', 'Sports & Racing', 'Uncategorized'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "_yuBJM_YyFr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c440400c-4acd-4b84-90dd-80faaf0c734b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 82758 entries, 16900 to 15796\n",
            "Data columns (total 40 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   steam_id               82758 non-null  object \n",
            " 1   name_info              82743 non-null  object \n",
            " 2   metacritic             82758 non-null  int64  \n",
            " 3   steam_achievements     82758 non-null  int64  \n",
            " 4   steam_trading_cards    82758 non-null  int64  \n",
            " 5   workshop_support       82758 non-null  int64  \n",
            " 6   genres                 82758 non-null  object \n",
            " 7   achievements_total     82758 non-null  int64  \n",
            " 8   release_date           82539 non-null  object \n",
            " 9   coming_soon            82758 non-null  float64\n",
            " 10  support_windows        82758 non-null  int64  \n",
            " 11  support_mac            82758 non-null  int64  \n",
            " 12  support_linux          82758 non-null  int64  \n",
            " 13  has_dlc                82758 non-null  int64  \n",
            " 14  has_demo               82758 non-null  int64  \n",
            " 15  name_dlc               82743 non-null  object \n",
            " 16  name_demo              82743 non-null  object \n",
            " 17  publisher              82685 non-null  object \n",
            " 18  developer              82749 non-null  object \n",
            " 19  is_free                82758 non-null  int64  \n",
            " 20  controller_support     82758 non-null  int64  \n",
            " 21  recommendations        82758 non-null  int64  \n",
            " 22  age_rating             82758 non-null  int64  \n",
            " 23  languages_clean_str    82758 non-null  object \n",
            " 24  price                  73007 non-null  float64\n",
            " 25  copiesSold             78101 non-null  float64\n",
            " 26  reviewScore            78101 non-null  float64\n",
            " 27  publisherClass         82758 non-null  int64  \n",
            " 28  standardized_date      71553 non-null  object \n",
            " 29  categories             82758 non-null  object \n",
            " 30  total_languages        82758 non-null  int64  \n",
            " 31  Casual & Social Games  82758 non-null  int64  \n",
            " 32  Core Games             82758 non-null  int64  \n",
            " 33  Creative Tools         82758 non-null  int64  \n",
            " 34  Education & Training   82758 non-null  int64  \n",
            " 35  Indie                  82758 non-null  int64  \n",
            " 36  Mature Content         82758 non-null  int64  \n",
            " 37  Productivity Tools     82758 non-null  int64  \n",
            " 38  Sports & Racing        82758 non-null  int64  \n",
            " 39  Uncategorized          82758 non-null  int64  \n",
            "dtypes: float64(4), int64(25), object(11)\n",
            "memory usage: 27.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(df.isnull().sum()/len(df))*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jD1gjSw9Of4M",
        "outputId": "6b427d0d-73e9-4fbc-d45d-a5752d3f6c3d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "steam_id                  0.000000\n",
              "name_info                 0.018125\n",
              "metacritic                0.000000\n",
              "steam_achievements        0.000000\n",
              "steam_trading_cards       0.000000\n",
              "workshop_support          0.000000\n",
              "genres                    0.000000\n",
              "achievements_total        0.000000\n",
              "release_date              0.264627\n",
              "coming_soon               0.000000\n",
              "support_windows           0.000000\n",
              "support_mac               0.000000\n",
              "support_linux             0.000000\n",
              "has_dlc                   0.000000\n",
              "has_demo                  0.000000\n",
              "name_dlc                  0.018125\n",
              "name_demo                 0.018125\n",
              "publisher                 0.088209\n",
              "developer                 0.010875\n",
              "is_free                   0.000000\n",
              "controller_support        0.000000\n",
              "recommendations           0.000000\n",
              "age_rating                0.000000\n",
              "languages_clean_str       0.000000\n",
              "price                    11.782547\n",
              "copiesSold                5.627251\n",
              "reviewScore               5.627251\n",
              "publisherClass            0.000000\n",
              "standardized_date        13.539477\n",
              "categories                0.000000\n",
              "total_languages           0.000000\n",
              "Casual & Social Games     0.000000\n",
              "Core Games                0.000000\n",
              "Creative Tools            0.000000\n",
              "Education & Training      0.000000\n",
              "Indie                     0.000000\n",
              "Mature Content            0.000000\n",
              "Productivity Tools        0.000000\n",
              "Sports & Racing           0.000000\n",
              "Uncategorized             0.000000\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>steam_id</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name_info</th>\n",
              "      <td>0.018125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metacritic</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>steam_achievements</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>steam_trading_cards</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>workshop_support</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genres</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>achievements_total</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>release_date</th>\n",
              "      <td>0.264627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>coming_soon</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support_windows</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support_mac</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support_linux</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>has_dlc</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>has_demo</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name_dlc</th>\n",
              "      <td>0.018125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name_demo</th>\n",
              "      <td>0.018125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>publisher</th>\n",
              "      <td>0.088209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>developer</th>\n",
              "      <td>0.010875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_free</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>controller_support</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recommendations</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_rating</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>languages_clean_str</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>11.782547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>copiesSold</th>\n",
              "      <td>5.627251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviewScore</th>\n",
              "      <td>5.627251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>publisherClass</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>standardized_date</th>\n",
              "      <td>13.539477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>categories</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_languages</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Casual &amp; Social Games</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Core Games</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Creative Tools</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Education &amp; Training</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Indie</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mature Content</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Productivity Tools</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sports &amp; Racing</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Uncategorized</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "HaZfd0GqWlDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shows that the developer and publisher columns\n",
        "# Have significant effect on the publisherClass\n",
        "# According to chi squared metric\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "def simple_publisher_analysis(df):\n",
        "    binary_cols = ['steam_achievements', 'steam_trading_cards', 'workshop_support',\n",
        "                   'controller_support', 'has_dlc', 'has_demo']\n",
        "    cat_cols = ['developer', 'age_rating', 'publisher']\n",
        "    num_cols = ['price']\n",
        "\n",
        "    if 'publisherClass' not in df.columns:\n",
        "        print(\"Error: 'publisherClass' column not found in dataframe\")\n",
        "        return\n",
        "\n",
        "    print(f\"{'Column':<20} {'Kendall Tau':<12} {'K p-value':<12} {'Test Type':<12} {'Statistic':<12} {'p-value':<12}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for col in binary_cols + cat_cols + num_cols:\n",
        "        if col not in df.columns:\n",
        "            print(f\"{col:<20} Not in dataframe\")\n",
        "            continue\n",
        "\n",
        "        valid_data = df[['publisherClass', col]].dropna()\n",
        "        if len(valid_data) == 0:\n",
        "            print(f\"{col:<20} No valid data\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            col_data = valid_data[col]\n",
        "            if col in cat_cols:\n",
        "                col_data = pd.factorize(col_data)[0]\n",
        "            tau, k_pval = stats.kendalltau(valid_data['publisherClass'], col_data)\n",
        "            k_result = f\"{tau:.4f}\", f\"{k_pval:.4f}\"\n",
        "        except:\n",
        "            k_result = \"Error\", \"Error\"\n",
        "\n",
        "        try:\n",
        "            if col in binary_cols or col in num_cols:\n",
        "                groups = []\n",
        "                for class_val in df['publisherClass'].unique():\n",
        "                    group = df[df['publisherClass'] == class_val][col].dropna()\n",
        "                    if len(group) > 0:\n",
        "                        groups.append(group)\n",
        "                if len(groups) >= 2:\n",
        "                    f_val, t_pval = stats.f_oneway(*groups)\n",
        "                    test_type = \"ANOVA\"\n",
        "                    test_result = f\"{f_val:.4f}\", f\"{t_pval:.4f}\"\n",
        "                else:\n",
        "                    test_type, test_result = \"ANOVA\", (\"N/A\", \"N/A\")\n",
        "            else:\n",
        "                table = pd.crosstab(df['publisherClass'], df[col])\n",
        "                chi2, t_pval, _, _ = chi2_contingency(table)\n",
        "                test_type = \"Chi2\"\n",
        "                test_result = f\"{chi2:.4f}\", f\"{t_pval:.4f}\"\n",
        "        except:\n",
        "            test_type, test_result = \"Error\", (\"Error\", \"Error\")\n",
        "\n",
        "        if col in ['developer', 'publisher']:\n",
        "            highlight_start = \"\\033[1;33m\"\n",
        "            highlight_end = \"\\033[0m\"\n",
        "        else:\n",
        "            highlight_start = \"\"\n",
        "            highlight_end = \"\"\n",
        "\n",
        "        print(f\"{highlight_start}{col:<20} {k_result[0]:<12} {k_result[1]:<12} {test_type:<12} {test_result[0]:<12} {test_result[1]:<12}{highlight_end}\")\n",
        "simple_publisher_analysis(fetch_df) # change the df"
      ],
      "metadata": {
        "id": "rWSc_ZJDVUhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PublisherClass distribution after different imputations technique\n",
        "def fill_publisher_class(df):\n",
        "    if 'publisher' in df.columns and 'publisherClass' in df.columns:\n",
        "        values_to_fill_mask = (df['publisherClass'] == -1) | (df['publisherClass'].isna())\n",
        "        publisher_mode_mapping = df[~values_to_fill_mask].groupby('publisher')['publisherClass'].agg(\n",
        "            lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
        "        ).to_dict()\n",
        "        mode_for_each_row = df['publisher'].map(publisher_mode_mapping)\n",
        "        fill_locations = values_to_fill_mask & mode_for_each_row.notna()\n",
        "        df.loc[fill_locations, 'publisherClass'] = mode_for_each_row[fill_locations]\n",
        "    elif 'developer' in df.columns and 'publisherClass' in df.columns:\n",
        "        values_to_fill_mask = (df['publisherClass'] == -1) | (df['publisherClass'].isna())\n",
        "        valid_df = df[~values_to_fill_mask]\n",
        "        if not valid_df.empty:\n",
        "            developer_mode_mapping = valid_df.groupby('developer')['publisherClass'].agg(\n",
        "                lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
        "            ).to_dict()\n",
        "            mode_for_each_row = df['developer'].map(developer_mode_mapping)\n",
        "            fill_locations = values_to_fill_mask & mode_for_each_row.notna()\n",
        "            df.loc[fill_locations, 'publisherClass'] = mode_for_each_row[fill_locations]\n",
        "    else:\n",
        "        if 'publisherClass' in df.columns:\n",
        "            mode_val = df['publisherClass'].mode()\n",
        "            if not mode_val.empty:\n",
        "                df['publisherClass'].fillna(mode_val[0], inplace=True)\n",
        "    return df\n",
        "def analyze_publisher_distributions(df):\n",
        "\n",
        "    df_original = df.copy()\n",
        "\n",
        "    pre_fill_data = df_original['publisherClass'].copy()\n",
        "\n",
        "    df_filled = fill_publisher_class(df_original.copy())\n",
        "\n",
        "    after_initial_fill = df_filled['publisherClass'].copy()\n",
        "\n",
        "    df_mode_filled = df_filled.copy()\n",
        "\n",
        "    mode_value = df_filled['publisherClass'].mode()[0]\n",
        "    df_mode_filled['publisherClass'] = df_mode_filled['publisherClass'].replace(-1, mode_value)\n",
        "    df_mode_filled['publisherClass'] = df_mode_filled['publisherClass'].fillna(mode_value)\n",
        "\n",
        "    df_dlc_filled = df_filled.copy()\n",
        "\n",
        "    if 'has_dlc' in df_dlc_filled.columns:\n",
        "\n",
        "        dlc_modes = df_dlc_filled.groupby('has_dlc')['publisherClass'].apply(\n",
        "            lambda x: x.mode()[0] if not x.mode().empty else mode_value)\n",
        "\n",
        "        for dlc_val in dlc_modes.index:\n",
        "            group_mode = dlc_modes[dlc_val]\n",
        "\n",
        "            mask_null = (df_dlc_filled['has_dlc'] == dlc_val) & (df_dlc_filled['publisherClass'].isna())\n",
        "            df_dlc_filled.loc[mask_null, 'publisherClass'] = group_mode\n",
        "\n",
        "            mask_neg = (df_dlc_filled['has_dlc'] == dlc_val) & (df_dlc_filled['publisherClass'] == -1)\n",
        "            df_dlc_filled.loc[mask_neg, 'publisherClass'] = group_mode\n",
        "    else:\n",
        "        df_dlc_filled = df_mode_filled.copy()\n",
        "\n",
        "    plt.figure(figsize=(20, 6))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    sns.histplot(pre_fill_data.dropna(), kde=True)\n",
        "    plt.title(\"Publisher Class Distribution\\n(Before Filling)\")\n",
        "    plt.xlabel(\"Publisher Class\")\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    sns.histplot(after_initial_fill.dropna(), kde=True)\n",
        "    plt.title(\"Publisher Class Distribution\\n(After Initial Filling)\")\n",
        "    plt.xlabel(\"Publisher Class\")\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    sns.histplot(df_mode_filled['publisherClass'], kde=True)\n",
        "    plt.title(\"Publisher Class Distribution\\n(After Mode Imputation)\")\n",
        "    plt.xlabel(\"Publisher Class\")\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    sns.histplot(df_dlc_filled['publisherClass'], kde=True)\n",
        "    plt.title(\"Publisher Class Distribution\\n(After has_dlc Mode Imputation)\")\n",
        "    plt.xlabel(\"Publisher Class\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    del df_original\n",
        "    del df_filled\n",
        "    del df_mode_filled\n",
        "    del df_dlc_filled\n",
        "    del after_initial_fill\n",
        "    del pre_fill_data\n",
        "\n",
        "analyze_publisher_distributions(fetch_df)  # change the df\n"
      ],
      "metadata": {
        "id": "NpyK_QXM9e4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_price_imputation_methods(df):\n",
        "\n",
        "    df_original = df.copy()\n",
        "\n",
        "    original_price = df_original['price'].copy()\n",
        "\n",
        "    before_imputation = original_price.copy()\n",
        "\n",
        "    df_has_dlc = df_original.copy()\n",
        "    df_publisher_class = df_original.copy()\n",
        "    df_mean = df_original.copy()\n",
        "    df_hierarchical = df_original.copy()\n",
        "    df_combined_enhanced = df_original.copy()\n",
        "\n",
        "    if 'has_dlc' in df.columns:\n",
        "\n",
        "        has_dlc_means = df_has_dlc.groupby('has_dlc')['price'].transform('mean')\n",
        "\n",
        "        price_nulls = df_has_dlc['price'].isna()\n",
        "        df_has_dlc.loc[price_nulls, 'price'] = has_dlc_means[price_nulls]\n",
        "    else:\n",
        "        print(\"Warning: has_dlc column not found\")\n",
        "\n",
        "    if 'publisherClass' in df.columns:\n",
        "\n",
        "        pub_class_means = df_publisher_class.groupby('publisherClass')['price'].transform('mean')\n",
        "\n",
        "        price_nulls = df_publisher_class['price'].isna()\n",
        "        df_publisher_class.loc[price_nulls, 'price'] = pub_class_means[price_nulls]\n",
        "    else:\n",
        "        print(\"Warning: publisherClass column not found\")\n",
        "\n",
        "    overall_mean = df_mean['price'].mean()\n",
        "    df_mean['price'].fillna(overall_mean, inplace=True)\n",
        "\n",
        "    df_hierarchical = fill_price_hierarchically_inplace(df_hierarchical)\n",
        "\n",
        "    required_cols = ['publisherClass', 'has_dlc', 'has_demo']\n",
        "    if all(col in df.columns for col in required_cols):\n",
        "\n",
        "        price_nulls = df_combined_enhanced['price'].isna()\n",
        "        null_indices = df_combined_enhanced[price_nulls].index\n",
        "\n",
        "        if len(null_indices) > 0:\n",
        "\n",
        "            pub_class_means = df_combined_enhanced.groupby('publisherClass')['price'].mean().to_dict()\n",
        "            has_dlc_means = df_combined_enhanced.groupby('has_dlc')['price'].mean().to_dict()\n",
        "            has_demo_means = df_combined_enhanced.groupby('has_demo')['price'].mean().to_dict()\n",
        "\n",
        "            np.random.seed(42)\n",
        "\n",
        "            for idx in null_indices:\n",
        "\n",
        "                row_pub_class = df_combined_enhanced.loc[idx, 'publisherClass']\n",
        "                row_has_dlc = df_combined_enhanced.loc[idx, 'has_dlc']\n",
        "                row_has_demo = df_combined_enhanced.loc[idx, 'has_demo']\n",
        "\n",
        "                if pd.isna(row_pub_class) or row_pub_class not in pub_class_means:\n",
        "                    pub_class_price = df_combined_enhanced['price'].mean()\n",
        "                else:\n",
        "                    pub_class_price = pub_class_means[row_pub_class]\n",
        "\n",
        "                if pd.isna(row_has_dlc) or row_has_dlc not in has_dlc_means:\n",
        "                    has_dlc_price = df_combined_enhanced['price'].mean()\n",
        "                else:\n",
        "                    has_dlc_price = has_dlc_means[row_has_dlc]\n",
        "\n",
        "                if pd.isna(row_has_demo) or row_has_demo not in has_demo_means:\n",
        "                    has_demo_price = df_combined_enhanced['price'].mean()\n",
        "                else:\n",
        "                    has_demo_price = has_demo_means[row_has_demo]\n",
        "\n",
        "                choices = [pub_class_price, has_dlc_price, has_demo_price]\n",
        "                weights = [0.35, 0.25, 0.4]\n",
        "                selected_price = np.random.choice(choices, p=weights)\n",
        "\n",
        "                df_combined_enhanced.loc[idx, 'price'] = selected_price\n",
        "    else:\n",
        "        print(\"Warning: Not all required columns present for enhanced combined approach\")\n",
        "\n",
        "        df_combined_enhanced['price'].fillna(df_combined_enhanced['price'].mean(), inplace=True)\n",
        "\n",
        "    plt.figure(figsize=(24, 4))\n",
        "\n",
        "    plt.subplot(1, 6, 1)\n",
        "    sns.histplot(before_imputation.dropna(), kde=True, color='blue')\n",
        "    plt.title(\"Price Distribution\\nBefore Imputation\")\n",
        "    plt.xlabel(\"Price\")\n",
        "    plt.xlim(0, 60)\n",
        "\n",
        "    plt.subplot(1, 6, 2)\n",
        "    sns.histplot(df_publisher_class['price'], kde=True, color='red')\n",
        "    plt.title(\"Price Distribution\\nAfter publisherClass Imputation\")\n",
        "    plt.xlabel(\"Price\")\n",
        "    plt.xlim(0, 60)\n",
        "\n",
        "    plt.subplot(1, 6, 3)\n",
        "    sns.histplot(df_has_dlc['price'], kde=True, color='green')\n",
        "    plt.title(\"Price Distribution\\nAfter has_dlc Imputation\")\n",
        "    plt.xlabel(\"Price\")\n",
        "    plt.xlim(0, 60)\n",
        "\n",
        "    plt.subplot(1, 6, 4)\n",
        "    sns.histplot(df_mean['price'], kde=True, color='orange')\n",
        "    plt.title(\"Price Distribution\\nAfter Mean Imputation\")\n",
        "    plt.xlabel(\"Price\")\n",
        "    plt.xlim(0, 60)\n",
        "\n",
        "    plt.subplot(1, 6, 5)\n",
        "    sns.histplot(df_combined_enhanced['price'], kde=True, color='magenta')\n",
        "    plt.title(\"Price Distribution\\nAfter Enhanced Combined Imputation\\n(with has_demo)\")\n",
        "    plt.xlabel(\"Price\")\n",
        "    plt.xlim(0, 60)\n",
        "\n",
        "    plt.subplot(1, 6, 6)\n",
        "    sns.histplot(df_hierarchical['price'], kde=True, color='teal')\n",
        "    plt.title(\"Price Distribution\\nAfter Hierarchical Imputation\")\n",
        "    plt.xlabel(\"Price\")\n",
        "    plt.xlim(0, 60)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    del df_original\n",
        "    del df_publisher_class\n",
        "    del df_has_dlc\n",
        "    del df_mean\n",
        "    del df_combined_enhanced\n",
        "    del df_hierarchical\n",
        "\n",
        "plot_price_imputation_methods(fetch_df)"
      ],
      "metadata": {
        "id": "HLa5DPv7lsKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "def plot_genre_imputation_comparison(df):\n",
        "\n",
        "    df_original = df.copy()\n",
        "    df_mode = df.copy()\n",
        "    df_combined = df.copy()\n",
        "    df_mean = df.copy()\n",
        "\n",
        "    original_genres = df_original['genres'].copy()\n",
        "\n",
        "    def get_genre_distribution(series):\n",
        "\n",
        "        genre_counts = Counter(series.dropna())\n",
        "\n",
        "        sorted_genres = dict(sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)[:10])\n",
        "        return sorted_genres\n",
        "\n",
        "    original_distribution = get_genre_distribution(original_genres)\n",
        "\n",
        "    price_mode = df_mode['price'].mode().iloc[0]\n",
        "    price_null_mask = df_mode['price'].isna()\n",
        "    df_mode.loc[price_null_mask, 'price'] = price_mode\n",
        "\n",
        "    df_mode = fill_missing_genres(df_mode)\n",
        "    mode_distribution = get_genre_distribution(df_mode['genres'])\n",
        "\n",
        "    df_combined = fill_missing_genres(df_combined)\n",
        "    combined_distribution = get_genre_distribution(df_combined['genres'])\n",
        "\n",
        "    price_mean = df_mean['price'].mean()\n",
        "    price_null_mask = df_mean['price'].isna()\n",
        "    df_mean.loc[price_null_mask, 'price'] = price_mean\n",
        "\n",
        "    df_mean = fill_missing_genres(df_mean)\n",
        "    mean_distribution = get_genre_distribution(df_mean['genres'])\n",
        "\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(20, 14))\n",
        "    fig.suptitle('Comparison of Genre Distributions After Different Imputation Methods', fontsize=20)\n",
        "\n",
        "    axs[0, 0].bar(original_distribution.keys(), original_distribution.values(), color='blue')\n",
        "    axs[0, 0].set_title('Original Genre Distribution (Before Imputation)')\n",
        "    axs[0, 0].set_xlabel('Genre')\n",
        "    axs[0, 0].set_ylabel('Count')\n",
        "    axs[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    axs[0, 1].bar(mode_distribution.keys(), mode_distribution.values(), color='green')\n",
        "    axs[0, 1].set_title('Genre Distribution After Mode Price Imputation')\n",
        "    axs[0, 1].set_xlabel('Genre')\n",
        "    axs[0, 1].set_ylabel('Count')\n",
        "    axs[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    axs[1, 0].bar(combined_distribution.keys(), combined_distribution.values(), color='red')\n",
        "    axs[1, 0].set_title('Genre Distribution After Combined (Publisher+Developer) Imputation')\n",
        "    axs[1, 0].set_xlabel('Genre')\n",
        "    axs[1, 0].set_ylabel('Count')\n",
        "    axs[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    axs[1, 1].bar(mean_distribution.keys(), mean_distribution.values(), color='orange')\n",
        "    axs[1, 1].set_title('Genre Distribution After Mean Price Imputation')\n",
        "    axs[1, 1].set_xlabel('Genre')\n",
        "    axs[1, 1].set_ylabel('Count')\n",
        "    axs[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.savefig('genre_imputation_comparison.png')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Change in genre counts after imputation:\")\n",
        "\n",
        "    def calc_percent_change(original, new, method_name):\n",
        "        all_genres = set(list(original.keys()) + list(new.keys()))\n",
        "        changes = []\n",
        "\n",
        "        for genre in all_genres:\n",
        "            orig_count = original.get(genre, 0)\n",
        "            new_count = new.get(genre, 0)\n",
        "\n",
        "            if orig_count == 0:\n",
        "                pct_change = \"New\"\n",
        "            else:\n",
        "                pct_change = f\"{((new_count - orig_count) / orig_count) * 100:.2f}%\"\n",
        "\n",
        "            changes.append((genre, orig_count, new_count, pct_change))\n",
        "\n",
        "        changes.sort(key=lambda x: abs(x[2] - x[1]) if isinstance(x[1], (int, float)) and isinstance(x[2], (int, float)) else 0, reverse=True)\n",
        "\n",
        "        print(f\"\\n{method_name}:\")\n",
        "        print(f\"{'Genre':<20} {'Original':<10} {'New':<10} {'% Change':<10}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        for genre, orig, new, pct in changes[:10]:\n",
        "            print(f\"{genre:<20} {orig:<10} {new:<10} {pct:<10}\")\n",
        "\n",
        "    del df_original\n",
        "    del df_mode\n",
        "    del df_combined\n",
        "    del df_mean\n",
        "\n",
        "plot_genre_imputation_comparison(fetch_df)"
      ],
      "metadata": {
        "id": "zqdH34q6lyaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pie chart showing the distribution of free vs. paid games\n",
        "\n",
        "free, not_free = df[df['price'] == 0].shape[0], df[df['price'] != 0].shape[0]\n",
        "\n",
        "labels = ['free', 'not free']\n",
        "\n",
        "fig = go.Figure(data=[go.Pie(labels=labels,\n",
        "                             values=[free, not_free])])\n",
        "\n",
        "fig.update_traces(textinfo='value', textfont_size=20,\n",
        "                  marker=dict(colors=['salmon', 'lightblue'],\n",
        "                  line=dict(color='#000000', width=2)))\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600, width=600, title_text='Free and not free games',\n",
        "    xaxis_title='number of songs', yaxis_title='artist', title_x = 0.5,\n",
        "\n",
        "    font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=18,\n",
        "            color=\"black\"),\n",
        "\n",
        "    legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=-0.2,\n",
        "            xanchor=\"right\",\n",
        "            x=0.75)\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vqEQK0uRWpDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart showing how many games support Windows, Mac, and Linux platforms\n",
        "# Almost all the games supports windows which indicates less importance of support_windows column\n",
        "\n",
        "windows = df['support_windows'].sum()\n",
        "mac = df['support_mac'].sum()\n",
        "linux = df['support_linux'].sum()\n",
        "\n",
        "labels = ['Windows', 'Mac', 'Linux']\n",
        "values = [windows, mac, linux]\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Bar(x=labels, y=values,\n",
        "                     marker_color='salmon'))\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600, width=500, title_text='Platform Support Frequency',\n",
        "    xaxis_title='Platform', yaxis_title='Count', title_x=0.5,\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=14,\n",
        "        color=\"black\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "p7CARX8DNodH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['standardized_date'] = pd.to_datetime(df['standardized_date'], errors='coerce')\n",
        "df['standardized_date']"
      ],
      "metadata": {
        "id": "lPGcZaXyh4Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart showing the number of Steam games released per year\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x = df['standardized_date'].dt.year.value_counts().index[:30],\n",
        "                     y  = df['standardized_date'].dt.year.value_counts().values[:30],\n",
        "                     marker_color = 'salmon' ))\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600, width=500, title_text='Steam games per year', yaxis_title='count', title_x = 0.5,\n",
        "\n",
        "    font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=14,\n",
        "            color=\"black\")\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "H6fu4GqzNqpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Line plot showing the number of games released each year\n",
        "\n",
        "df['standardized_dates'] = df['standardized_date'].dt.year\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['standardized_dates'].value_counts().sort_index().plot(kind='line')\n",
        "plt.title('Number of Games Released Over the Years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Games')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XHtMNv9RNsPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart showing the top 50 Steam developers by number of game releases\n",
        "\n",
        "top_10_devs = df['developer'].value_counts().sort_values(ascending=False).head(50)\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Bar(x=top_10_devs.index, y=top_10_devs.values, marker_color='salmon'))\n",
        "\n",
        "fig.update_layout(\n",
        "    height=800, width=600, title_text='TOP 10 STEAM DEVELOPERS', yaxis_title='count', title_x = 0.5,\n",
        "\n",
        "    font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=14,\n",
        "            color=\"black\")\n",
        ")\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "qArUKAReNtkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart showing the top 25 Steam publishers by number of game releases\n",
        "\n",
        "top_10_publishers = df['publisher'].value_counts().sort_values(ascending=False).head(25)\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Bar(x=top_10_publishers.index, y=top_10_publishers.values, marker_color='salmon'))\n",
        "\n",
        "fig.update_layout(\n",
        "    height=800, width=600, title_text='TOP 10 STEAM PUBLISHERS', yaxis_title='count', title_x = 0.5,\n",
        "\n",
        "    font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=14,\n",
        "            color=\"black\")\n",
        ")\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "s0plIqzSNvI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot showing the distribution of age ratings for Steam games\n",
        "\n",
        "df1 = df.copy()\n",
        "df1['age_rating'] = df1['age_rating'].astype(str)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='age_rating', data=df1)\n",
        "plt.title('Boxplot of Required Age for Games')\n",
        "plt.xlabel('Required Age')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AOMIl2VZNu7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot to explore the relationship between game recommendations and price\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='recommendations', y='price', data=df)\n",
        "plt.title('Scatter Plot of Recommendations vs Price Overview')\n",
        "plt.xlabel('Recommendations')\n",
        "plt.ylabel('Price Overview')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MPADCbPHN9Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_df.columns"
      ],
      "metadata": {
        "id": "peLuq3HIiqL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "no column called categories changed it to genres\n"
      ],
      "metadata": {
        "id": "eDr19wmjjEIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizes the number of games per category\n",
        "\n",
        "fetch_df2 = fetch_df.copy()\n",
        "\n",
        "def process_categories(categories):\n",
        "    if isinstance(categories, list):\n",
        "        return [item.strip().lower() for item in categories]\n",
        "    elif isinstance(categories, str):\n",
        "        return [item.strip().lower() for item in categories.split(',')]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "fetch_df2['genre_splitted'] = fetch_df2['genres'].apply(process_categories) #here only\n",
        "genre_counts = fetch_df2['genre_splitted'].explode().value_counts()\n",
        "df2 = pd.DataFrame({'categories': genre_counts.index, 'Number of Games': genre_counts.values})\n",
        "\n",
        "fig = px.bar(df2, x='categories', y='Number of Games', text='Number of Games', title='Number of Games per Category',\n",
        "             labels={'Number of Games': 'Number of Games', 'categories': 'Categories'})\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis=dict(\n",
        "        tickangle=45,\n",
        "        tickmode='array',\n",
        "        tickvals=list(range(len(genre_counts.index))),\n",
        "        ticktext=genre_counts.index\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "kHA9MddcN_ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Horizontal bar chart of the top 10 games by number of recommendations\n",
        "\n",
        "df['recommendations'] = pd.to_numeric(df['recommendations'], errors='coerce')\n",
        "\n",
        "print(\"Max recommendations before filtering:\", df['recommendations'].max())\n",
        "max_recommendations_row = df[df['recommendations'] == df['recommendations'].max()]\n",
        "print(\"\\nRow with max recommendations:\")\n",
        "print(max_recommendations_row[['name_info', 'recommendations']].to_string(index=False))\n",
        "\n",
        "filtered_df = df[df['recommendations'] <= 16000000]\n",
        "\n",
        "top_10_games = filtered_df.nlargest(10, 'recommendations')\n",
        "\n",
        "fig = px.bar(\n",
        "    top_10_games,\n",
        "    x='name_info',\n",
        "    y='recommendations',\n",
        "    title='Top 10 Games by Recommendations',\n",
        "    labels={'recommendations': 'Recommendations', 'name_info': 'Game'},\n",
        ")\n",
        "fig.update_layout(xaxis_tickangle=-45, height=600, width=900, title_x=0.5)\n",
        "fig.update_traces(textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "K6ftzlNQOAN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram that shows the distribution of game prices\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['price'], bins=10, kde=True)\n",
        "plt.title(\"Price Distribution of Games\")\n",
        "plt.xlabel(\"Price\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.xlim(0, df['price'].max())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ELlV0joMODCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluates the relationship between features and 'copiesSold'\n",
        "\n",
        "df['age_rating'] = pd.to_numeric(df['age_rating'], errors='coerce')\n",
        "\n",
        "temp = ['copiesSold','name_info','steam_id','metacritic','achievements_total','developer','publisher','recommendations','age_rating','price','reviewScore','standardized_date','standardized_dates','languages_clean_str']\n",
        "X = df.drop(columns=temp)\n",
        "y = df['copiesSold']\n",
        "\n",
        "# Show columns with non-numeric data types\n",
        "non_numeric_cols = X.select_dtypes(exclude=['number']).columns\n",
        "print(\"Non-numeric columns in X:\")\n",
        "print(non_numeric_cols)\n",
        "\n",
        "selector = SelectKBest(score_func=f_regression, k='all')\n",
        "selector.fit(X, y)\n",
        "\n",
        "scores = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'F_score': selector.scores_,\n",
        "    'p_value': selector.pvalues_\n",
        "}).sort_values('F_score', ascending=False)\n",
        "\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "v4CsUL_qOFBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computes Kendall’s Tau correlation and corresponding p-values between features and 'copiesSold'\n",
        "\n",
        "taus = []\n",
        "pvals = []\n",
        "for col in X.columns:\n",
        "    mask = X[col].notna() & y.notna()\n",
        "    if mask.sum() < 2:\n",
        "        tau, p = 0.0, 1.0\n",
        "    else:\n",
        "        tau, p = kendalltau(X.loc[mask, col], y.loc[mask])\n",
        "    taus.append(tau)\n",
        "    pvals.append(p)\n",
        "\n",
        "kendall_df = pd.DataFrame({\n",
        "    'feature':    X.columns,\n",
        "    'kendall_tau': taus,\n",
        "    'p_value':    pvals\n",
        "})\n",
        "\n",
        "kendall_df['abs_tau'] = kendall_df['kendall_tau'].abs()\n",
        "kendall_df = kendall_df.sort_values('abs_tau', ascending=False)\n",
        "print(kendall_df)"
      ],
      "metadata": {
        "id": "RPS3qiRLOJ1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heatmap showing the correlation matrix between 'copiesSold' and selected numerical features\n",
        "\n",
        "corr = df[['copiesSold', 'price', 'metacritic', 'recommendations', 'steam_achievements', 'total_languages']].corr()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Correlation with Copies Sold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g7q9wgqeOPmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart of the median copies sold per genre\n",
        "\n",
        "genres = ['Indie', 'Core Games', 'Sports & Racing', 'Casual & Social Games']\n",
        "genre_sales = df.groupby(genres)['copiesSold'].mean().reset_index()\n",
        "genre_sales = genre_sales.melt(id_vars='copiesSold', var_name='Genre', value_name='Has_Genre')\n",
        "genre_sales = genre_sales[genre_sales['Has_Genre'] == 1]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='Genre', y='copiesSold', data=genre_sales, estimator=np.median)\n",
        "plt.title('Median Copies Sold by Genre')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z0Sn-PfjO0Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot comparing copies sold between free and paid games\n",
        "\n",
        "sns.boxplot(x='is_free', y='copiesSold', data=df)\n",
        "plt.title('Copies Sold: Free vs. Paid Games')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UUt4tIAWO1F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Violin plot showing the distribution of copies sold grouped by controller support status\n",
        "\n",
        "sns.violinplot(x='controller_support', y='copiesSold', data=df)\n",
        "plt.title('Copies Sold by Controller Support')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WlMGGrOQO3qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Horizontal bar chart of the top 10 publishers by median copies sold\n",
        "\n",
        "top_publishers = df.groupby('publisher')['copiesSold'].median().sort_values(ascending=False).head(10)\n",
        "sns.barplot(x=top_publishers.values, y=top_publishers.index)\n",
        "plt.title('Top 10 Publishers by Median Copies Sold')\n",
        "plt.xlabel('Median Copies Sold (Log Scale)')\n",
        "plt.xscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xkJ4JDF0O5Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 best-selling games along with their price, metacritic score, and publisher\n",
        "\n",
        "top_games = df.nlargest(10, 'copiesSold')[['name_info', 'copiesSold', 'price', 'metacritic', 'publisher']]\n",
        "print(\"Top 10 Best-Selling Games:\")\n",
        "print(top_games.to_string(index=False))"
      ],
      "metadata": {
        "id": "bF5PRuNbO7EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🎮 Feature Engineering"
      ],
      "metadata": {
        "id": "9wnER5GHp2SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_game_age(df):\n",
        "    df = df.copy()\n",
        "    current_year = datetime.now().year\n",
        "    df['game_age'] = df['standardized_date'].apply(\n",
        "        lambda x: current_year - x.year if pd.notna(x) else None\n",
        "    )\n",
        "    df['game_age'] = df['game_age'].fillna(df['game_age'].median())\n",
        "    return df"
      ],
      "metadata": {
        "id": "RRSdswtrxkA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_publisher_developer_popularity(df, publisher_avg_recs=None, developer_avg_recs=None,\n",
        "                                          publisher_avg_price=None, developer_avg_price=None):\n",
        "    df = df.copy()\n",
        "    # Count number of games per publisher and developer\n",
        "    publisher_counts = df['publisher'].value_counts().to_dict()\n",
        "    developer_counts = df['developer'].value_counts().to_dict()\n",
        "    df['publisher_games_count'] = df['publisher'].map(publisher_counts).fillna(1)\n",
        "    df['developer_games_count'] = df['developer'].map(developer_counts).fillna(1)\n",
        "\n",
        "    # Compute or apply average recommendations\n",
        "    if publisher_avg_recs is None:\n",
        "        publisher_avg_recs = df.groupby('publisher')['recommendations'].mean().to_dict()\n",
        "        developer_avg_recs = df.groupby('developer')['recommendations'].mean().to_dict()\n",
        "    df['publisher_avg_recs'] = df['publisher'].map(publisher_avg_recs).fillna(df['recommendations'].mean())\n",
        "    df['developer_avg_recs'] = df['developer'].map(developer_avg_recs).fillna(df['recommendations'].mean())\n",
        "\n",
        "    # Compute or apply average price\n",
        "    if publisher_avg_price is None:\n",
        "        publisher_avg_price = df.groupby('publisher')['price'].mean().to_dict()\n",
        "        developer_avg_price = df.groupby('developer')['price'].mean().to_dict()\n",
        "    df['publisher_avg_price'] = df['publisher'].map(publisher_avg_price).fillna(df['price'].mean())\n",
        "    df['developer_avg_price'] = df['developer'].map(developer_avg_price).fillna(df['price'].mean())\n",
        "\n",
        "    return df, publisher_avg_recs, developer_avg_recs, publisher_avg_price, developer_avg_price"
      ],
      "metadata": {
        "id": "9MscLP3ZxnwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_price_recommendation_ratio(df):\n",
        "    df = df.copy()\n",
        "    df['price_recommendation_ratio'] = df['recommendations'] / (df['price'] + 1)  # Add 1 to avoid division by zero\n",
        "    df['price_recommendation_ratio'] = df['price_recommendation_ratio'].fillna(0)\n",
        "    return df"
      ],
      "metadata": {
        "id": "ZXvoL88kxqZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_genre_interactions(df):\n",
        "    df = df.copy()\n",
        "    key_genres = ['Indie', 'Core Games', 'Casual & Social Games']\n",
        "    for genre in key_genres:\n",
        "        if genre in df.columns:\n",
        "            df[f'{genre}_price'] = df[genre] * df['price']\n",
        "            df[f'{genre}_languages'] = df[genre] * df['total_languages']\n",
        "    return df"
      ],
      "metadata": {
        "id": "MsiUYp3XxsvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new column contains 0/1 if this publisher from top 10 according to mean of copiesSold\n",
        "def create_top_publisher_feature(df, top_publishers=None):\n",
        "    df = df.copy()\n",
        "    if top_publishers is None:\n",
        "        # During training, compute top publishers\n",
        "        top_publishers = df.groupby('publisher')['copiesSold'].median().sort_values(ascending=False).head(10).index\n",
        "        df['is_top_publisher'] = df['publisher'].isin(top_publishers).astype(int)\n",
        "        return df, top_publishers\n",
        "    else:\n",
        "        # During validation/test, use provided top publishers\n",
        "        df['is_top_publisher'] = df['publisher'].isin(top_publishers).astype(int)\n",
        "        return df"
      ],
      "metadata": {
        "id": "eLnLooCBxvCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_multi_platform_support(df):\n",
        "    df = df.copy()\n",
        "    df['non_windows_platforms'] = df[['support_mac', 'support_linux']].sum(axis=1)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-szVUtZ6xzwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_additional_features(df, genre_scores=None):\n",
        "    df = df.copy()\n",
        "    # Game age bins\n",
        "    # Replace negative or invalid ages with NaN\n",
        "    df['game_age_clean'] = df['game_age'].apply(lambda x: x if x >= 0 else np.nan)\n",
        "\n",
        "    #fill nulls\n",
        "    median_age = df['game_age_clean'].median()\n",
        "    df['game_age_clean'] = df['game_age_clean'].fillna(median_age)\n",
        "\n",
        "    # Define bins and labels\n",
        "    bins = [0, 1, 3, 6, 10, 20, float('inf')]\n",
        "    labels = ['new', 'recent', 'established', 'veteran', 'classic', 'retro']\n",
        "\n",
        "    # Apply binning\n",
        "    df['game_age_bin'] = pd.cut(df['game_age_clean'], bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "    # One-hot encode the bins\n",
        "    df = pd.get_dummies(df, columns=['game_age_bin'], prefix='age_bin')\n",
        "\n",
        "    return df\n",
        "\n",
        "    # Recommendations-to-languages ratio\n",
        "    df['recs_to_languages_ratio'] = df['recommendations'] / (df['total_languages'] + 1)  # Add 1 to avoid division by zero\n",
        "    df['recs_to_languages_ratio'] = df['recs_to_languages_ratio'].fillna(0)\n",
        "\n",
        "    # Genre popularity score\n",
        "    key_genres = ['Indie', 'Core Games', 'Casual & Social Games']\n",
        "    if genre_scores is None:\n",
        "        genre_scores = {}\n",
        "        for genre in key_genres:\n",
        "            if genre in df.columns:\n",
        "                genre_scores[genre] = df[df[genre] == 1]['recommendations'].mean() if df[genre].sum() > 0 else 0\n",
        "    df['genre_popularity_score'] = df[key_genres].apply(\n",
        "        lambda x: sum(genre_scores.get(genre, 0) for genre in key_genres if x[genre] == 1), axis=1\n",
        "    )\n",
        "\n",
        "    # Free game indicator\n",
        "    df['is_free_game'] = (df['price'] == 0).astype(int)\n",
        "\n",
        "    return df, genre_scores"
      ],
      "metadata": {
        "id": "lqlNXI_k8hdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering Function\n",
        "def feature_eng(df, top_publishers=None, publisher_avg_recs=None, developer_avg_recs=None,\n",
        "                publisher_avg_price=None, developer_avg_price=None, genre_scores=None):\n",
        "    df = compute_game_age(df)\n",
        "    df, publisher_avg_recs, developer_avg_recs, publisher_avg_price, developer_avg_price = compute_publisher_developer_popularity(\n",
        "        df, publisher_avg_recs, developer_avg_recs, publisher_avg_price, developer_avg_price\n",
        "    )\n",
        "    df = compute_price_recommendation_ratio(df)\n",
        "    df = create_genre_interactions(df)\n",
        "    if top_publishers is None:\n",
        "        df, top_publishers = create_top_publisher_feature(df)\n",
        "    else:\n",
        "        df = create_top_publisher_feature(df, top_publishers=top_publishers)\n",
        "    df = compute_multi_platform_support(df)\n",
        "    df, genre_scores = compute_additional_features(df, genre_scores)\n",
        "    return df, {\n",
        "        'top_publishers': top_publishers,\n",
        "        'publisher_avg_recs': publisher_avg_recs,\n",
        "        'developer_avg_recs': developer_avg_recs,\n",
        "        'publisher_avg_price': publisher_avg_price,\n",
        "        'developer_avg_price': developer_avg_price,\n",
        "        'genre_scores': genre_scores\n",
        "    }"
      ],
      "metadata": {
        "id": "Z3_bNaZUx4pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CopyDF = df.copy()\n",
        "CopyDF, precomputed = feature_eng(CopyDF)\n",
        "CopyDF.columns"
      ],
      "metadata": {
        "id": "-ApQLIKlyHBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CopyDF['game_age'].unique()"
      ],
      "metadata": {
        "id": "HBPiSjSiMgc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of game_age vs copiesSold\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='game_age', y='copiesSold', data=CopyDF)\n",
        "plt.title('Game Age vs Copies Sold')\n",
        "plt.xlabel('Game Age (Years)')\n",
        "plt.ylabel('Copies Sold')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-aFa3n5_1PAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot of copiesSold by is_top_publisher\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='is_top_publisher', y='copiesSold', data=CopyDF)\n",
        "plt.title('Copies Sold by Top Publisher Status')\n",
        "plt.xlabel('Is Top Publisher')\n",
        "plt.ylabel('Copies Sold')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0ZtNW-_E1Z9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart of mean copiesSold by non_windows_platforms\n",
        "platform_sales = CopyDF.groupby('non_windows_platforms')['copiesSold'].mean().reset_index()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='non_windows_platforms', y='copiesSold', data=platform_sales)\n",
        "plt.title('Mean Copies Sold by Number of Non-Windows Platforms')\n",
        "plt.xlabel('Number of Non-Windows Platforms')\n",
        "plt.ylabel('Mean Copies Sold')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VG6elXop1fh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation heatmap with new features\n",
        "new_features = ['game_age', 'publisher_games_count', 'developer_games_count',\n",
        "                'publisher_avg_recs', 'developer_avg_recs', 'publisher_avg_price', 'developer_avg_price',\n",
        "                'price_recommendation_ratio', 'is_top_publisher', 'non_windows_platforms',\n",
        "                'recs_to_languages_ratio', 'genre_popularity_score', 'is_free_game',\n",
        "                'Indie_price', 'Core Games_price', 'Casual & Social Games_price',\n",
        "                'recommendations', 'copiesSold']\n",
        "# Filter out features not in CopyDF\n",
        "new_features = [f for f in new_features if f in CopyDF.columns]\n",
        "corr = CopyDF[new_features].corr()\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt='.2f')\n",
        "plt.title('Correlation Matrix with New Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jEcN9c1y11aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#From all of the above the new features would be:\n",
        "# metacritic, recomendations, publisher_avg_recs, developer_avg_recs, price_recommendation_ratio, is_top_publisher, recs_to_languages_ratio"
      ],
      "metadata": {
        "id": "QmJtTyTA2zJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply pipeline to Validation and Test data"
      ],
      "metadata": {
        "id": "sgn2db5LRfi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_df = pipeline.transform(val_df)\n",
        "# test_df = pipeline.transform(test_df)"
      ],
      "metadata": {
        "id": "YlkD9HM9Q7I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "01fos59FRGEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # We need to test our feature selection\n",
        "# columns_to_drop = ['copiesSold', 'steam_id', 'name_info', 'publisher', 'developer',\n",
        "#                    'languages', 'standardized_dates', 'languages_clean_str', 'standardized_date']\n",
        "\n",
        "# X_train = df.drop(columns=columns_to_drop)\n",
        "# y_train = df['copiesSold']\n",
        "\n",
        "# X_val = val_df.drop(columns=columns_to_drop)\n",
        "# y_val = val_df['copiesSold']\n",
        "\n",
        "# X_test = test_df.drop(columns=columns_to_drop)\n",
        "# y_test = test_df['copiesSold']"
      ],
      "metadata": {
        "id": "qvEG8T68RSGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use instead of GridSearchCV\n",
        "# def manual_grid_search_generic(model_class, param_grid, X_train, y_train, X_val, y_val, fixed_params=None):\n",
        "#     from itertools import product\n",
        "\n",
        "#     best_score = -float('inf')\n",
        "#     best_model = None\n",
        "#     best_params = None\n",
        "\n",
        "#     fixed_params = fixed_params or {}\n",
        "#     keys, values = zip(*param_grid.items()) if param_grid else ([], [])\n",
        "\n",
        "#     for combo in product(*values) if keys else [()]:\n",
        "#         params = dict(zip(keys, combo)) if keys else {}\n",
        "#         full_params = {**fixed_params, **params}\n",
        "#         model = model_class(**full_params)\n",
        "#         model.fit(X_train, y_train)\n",
        "#         val_score = r2_score(y_val, model.predict(X_val))\n",
        "\n",
        "#         if val_score > best_score:\n",
        "#             best_score = val_score\n",
        "#             best_model = model\n",
        "#             best_params = full_params\n",
        "\n",
        "#     return best_model, best_params, best_score\n",
        "\n",
        "#     results = {}\n",
        "#     def evaluate_sets(model, X_train, y_train, X_val, y_val, X_test, y_test, name):\n",
        "#     results[name] = {}  # Create nested dict for this model\n",
        "#     for X, y, label in zip([X_train, X_val, X_test], [y_train, y_val, y_test], ['Train', 'Validation', 'Test']):\n",
        "#         y_pred = model.predict(X)\n",
        "#         r2 = r2_score(y, y_pred)\n",
        "#         results[name][f\"{label} R²\"] = r2\n",
        "#         print(f\"{label} Accuracy (R²): {r2 * 100:.2f}%\")\n",
        "#     print(\"=\" * 48)\n",
        "#     return results[name]['Train R²'], results[name]['Validation R²'], results[name]['Test R²']\n",
        "\n",
        "#     def print_accuracy_summary(model_name, train_r2, val_r2, test_r2, results_dict):\n",
        "#     results_dict[model_name] = {\n",
        "#         'Train R²': train_r2,\n",
        "#         'Validation R²': val_r2,\n",
        "#         'Test R²': test_r2\n",
        "#     }\n",
        "\n",
        "#     print(f\"📊 Accuracy Summary for {model_name}\")\n",
        "#     print(f\"Train R²:       {train_r2:.4f} ({train_r2 * 100:.2f}%)\")\n",
        "#     print(f\"Validation R²:  {val_r2:.4f} ({val_r2 * 100:.2f}%)\")\n",
        "#     print(f\"Test R²:        {test_r2:.4f} ({test_r2 * 100:.2f}%)\")\n",
        "#     print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "9Y1dLbZjZAau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Linear, Lasso, Ridge Regressors\n",
        "\n",
        "# models = {\n",
        "#     'Linear Regression': {\n",
        "#         'class': LinearRegression,\n",
        "#         'params': {},\n",
        "#         'fixed': {}\n",
        "#     },\n",
        "#     'Lasso Regression': {\n",
        "#         'class': Lasso,\n",
        "#         'params': {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]},\n",
        "#         'fixed': {'random_state': 42}\n",
        "#     },\n",
        "#     'Ridge Regression': {\n",
        "#         'class': Ridge,\n",
        "#         'params': {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]},\n",
        "#         'fixed': {'random_state': 42}\n",
        "#     },\n",
        "# }\n",
        "\n",
        "# results = {}\n",
        "\n",
        "# for name, model_info in models.items():\n",
        "#     print(f\"🔍 Tuning {name}\")\n",
        "#     best_model, best_params, best_val_r2 = manual_grid_search_generic(\n",
        "#         model_info['class'],\n",
        "#         model_info['params'],\n",
        "#         X_train, y_train,\n",
        "#         X_val, y_val,\n",
        "#         fixed_params=model_info.get('fixed')\n",
        "#     )\n",
        "#     print(f\"Best Params: {best_params}\")\n",
        "#     train_r2, val_r2, test_r2 = evaluate_sets(best_model, X_train, y_train, X_val, y_val, X_test, y_test, name)\n",
        "#     print_accuracy_summary(name, train_r2, val_r2, test_r2, results)\n"
      ],
      "metadata": {
        "id": "_XPbCtcESdBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # MLP Regressor\n",
        "\n",
        "# mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=5000, random_state=42)\n",
        "# mlp.fit(X_train, y_train)\n",
        "# train_r2, val_r2, test_r2 = evaluate_sets(mlp, X_train, y_train, X_val, y_val, X_test, y_test, 'MLP Regressor')\n",
        "\n",
        "# print_accuracy_summary('MLP Regressor', train_r2, val_r2, test_r2, results)"
      ],
      "metadata": {
        "id": "Keeb2_5ISmdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # CatBoost Regressor\n",
        "\n",
        "# cat_model, cat_params, cat_val_r2 = manual_grid_search_generic(\n",
        "#     CatBoostRegressor,\n",
        "#     param_grid_cat,\n",
        "#     X_train, y_train,\n",
        "#     X_val, y_val,\n",
        "#     fixed_params={'random_state': 42, 'verbose': 0}\n",
        "# )\n",
        "# print(\"Best CatBoost Params:\", cat_params)\n",
        "# train_r2, val_r2, test_r2 = evaluate_sets(cat_model, X_train, y_train, X_val, y_val, X_test, y_test, 'CatBoost')\n",
        "# print_accuracy_summary('CatBoost', train_r2, val_r2, test_r2, results)"
      ],
      "metadata": {
        "id": "JL8lIdkmb_4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}